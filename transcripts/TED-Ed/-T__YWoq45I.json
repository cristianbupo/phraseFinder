[
  {
    "text": "What's the most important century\nin human history?",
    "start": 7.003,
    "duration": 3.587
  },
  {
    "text": "Some might argue it’s a period \nof extensive military campaigning,",
    "start": 11.049,
    "duration": 3.92
  },
  {
    "text": "like Alexander the Great’s \nin the 300s BCE,",
    "start": 14.969,
    "duration": 3.545
  },
  {
    "text": "which reshaped political\nand cultural borders.",
    "start": 18.848,
    "duration": 3.253
  },
  {
    "text": "Others might cite the emergence \nof a major religion,",
    "start": 23.936,
    "duration": 3.087
  },
  {
    "text": "such as Islam in the 7th century,",
    "start": 27.023,
    "duration": 2.127
  },
  {
    "text": "which codified and spread values\nacross such borders.",
    "start": 29.525,
    "duration": 3.504
  },
  {
    "text": "Or perhaps it’s the Industrial Revolution\nof the 1700s",
    "start": 35.531,
    "duration": 3.462
  },
  {
    "text": "that transformed global commerce",
    "start": 38.993,
    "duration": 1.752
  },
  {
    "text": "and redefined humanity's relationship\nwith labor.",
    "start": 40.745,
    "duration": 3.128
  },
  {
    "text": "Whatever the answer, it seems like \nany century vying for that top spot",
    "start": 44.165,
    "duration": 4.129
  },
  {
    "text": "is at a moment of great change—",
    "start": 48.294,
    "duration": 2.377
  },
  {
    "text": "when the actions of our ancestors shifted\nhumanity’s trajectory",
    "start": 51.631,
    "duration": 4.171
  },
  {
    "text": "for centuries to come.",
    "start": 55.802,
    "duration": 1.584
  },
  {
    "text": "So if this is our metric, \nis it possible that right now—",
    "start": 57.72,
    "duration": 3.921
  },
  {
    "text": "this century— \nis the most important one yet?",
    "start": 61.641,
    "duration": 3.086
  },
  {
    "text": "The 21st century has already proven to be\na period of rapid technological growth.",
    "start": 65.77,
    "duration": 5.213
  },
  {
    "text": "Phones and computers have accelerated\nthe pace of life.",
    "start": 71.234,
    "duration": 3.128
  },
  {
    "text": "And we’re likely on the cusp of developing\nnew transformative technologies,",
    "start": 74.403,
    "duration": 4.171
  },
  {
    "text": "like advanced artificial intelligence,",
    "start": 78.574,
    "duration": 2.294
  },
  {
    "text": "that could entirely change \nthe way people live.",
    "start": 80.868,
    "duration": 2.878
  },
  {
    "text": "Meanwhile, many technologies \nwe already have",
    "start": 85.414,
    "duration": 3.045
  },
  {
    "text": "contribute to humanity’s unprecedented \nlevels of existential risk—",
    "start": 88.459,
    "duration": 4.838
  },
  {
    "text": "that’s the risk of our\nspecies going extinct",
    "start": 93.381,
    "duration": 2.377
  },
  {
    "text": "or experiencing some kind of disaster\nthat permanently limits",
    "start": 95.758,
    "duration": 3.42
  },
  {
    "text": "humanity’s ability to grow and thrive.",
    "start": 99.178,
    "duration": 2.67
  },
  {
    "text": "The invention of the atomic bomb marked\na major rise in existential risk,",
    "start": 103.266,
    "duration": 4.629
  },
  {
    "text": "and since then we’ve only increased\nthe odds against us.",
    "start": 108.396,
    "duration": 3.879
  },
  {
    "text": "It’s profoundly difficult\nto estimate the odds",
    "start": 112.9,
    "duration": 2.628
  },
  {
    "text": "of an existential collapse \noccurring this century.",
    "start": 115.528,
    "duration": 2.628
  },
  {
    "text": "Very rough guesses put the risk \nof existential catastrophe",
    "start": 118.239,
    "duration": 3.462
  },
  {
    "text": "due to nuclear winter and climate change\nat around 0.1%,",
    "start": 121.701,
    "duration": 4.88
  },
  {
    "text": "with the odds of a pandemic causing\nthe same kind of collapse",
    "start": 128.291,
    "duration": 3.211
  },
  {
    "text": "at a frightening 3%.",
    "start": 131.502,
    "duration": 1.96
  },
  {
    "text": "Given that any of these disasters could \nmean the end of life as we know it,",
    "start": 134.005,
    "duration": 4.88
  },
  {
    "text": "these aren’t exactly small figures,",
    "start": 139.177,
    "duration": 2.127
  },
  {
    "text": "And it’s possible this century could see\nthe rise of new technologies",
    "start": 141.304,
    "duration": 4.004
  },
  {
    "text": "that introduce more existential risks.",
    "start": 145.308,
    "duration": 2.794
  },
  {
    "text": "AI experts have a wide range \nof estimates regarding",
    "start": 149.103,
    "duration": 2.628
  },
  {
    "text": "when artificial general intelligence\nwill emerge,",
    "start": 151.731,
    "duration": 2.961
  },
  {
    "text": "but according to some surveys,\nmany believe it could happen this century.",
    "start": 154.734,
    "duration": 4.087
  },
  {
    "text": "Currently, we have relatively narrow forms\nof artificial intelligence,",
    "start": 159.655,
    "duration": 3.837
  },
  {
    "text": "which are designed to do specific tasks \nlike play chess or recognize faces.",
    "start": 163.492,
    "duration": 4.588
  },
  {
    "text": "Even narrow AIs that do creative work are\nlimited to their singular specialty.",
    "start": 169.04,
    "duration": 5.213
  },
  {
    "text": "But artificial general intelligences,\nor AGIs,",
    "start": 174.503,
    "duration": 3.629
  },
  {
    "text": "would be able to adapt to and\nperform any number of tasks,",
    "start": 178.132,
    "duration": 3.837
  },
  {
    "text": "quickly outpacing \ntheir human counterparts.",
    "start": 182.678,
    "duration": 2.878
  },
  {
    "text": "There are a huge variety of guesses\nabout what AGI could look like,",
    "start": 186.849,
    "duration": 4.088
  },
  {
    "text": "and what it would mean\nfor humanity to share the Earth",
    "start": 191.646,
    "duration": 2.836
  },
  {
    "text": "with another sentient entity.",
    "start": 194.482,
    "duration": 2.127
  },
  {
    "text": "AGIs might help us achieve our goals,",
    "start": 198.653,
    "duration": 2.544
  },
  {
    "text": "they might regard us as inconsequential,",
    "start": 201.197,
    "duration": 2.294
  },
  {
    "text": "or, they might see us as an obstacle\nto swiftly remove.",
    "start": 203.491,
    "duration": 3.17
  },
  {
    "text": "So in terms of existential risk,",
    "start": 206.869,
    "duration": 2.169
  },
  {
    "text": "it's imperative the values of this new\ntechnology align with our own.",
    "start": 209.038,
    "duration": 4.087
  },
  {
    "text": "This is an incredibly difficult\nphilosophical and engineering challenge",
    "start": 213.501,
    "duration": 3.879
  },
  {
    "text": "that will require a lot \nof delicate, thoughtful work.",
    "start": 217.38,
    "duration": 3.086
  },
  {
    "text": "Yet, even if we succeed, AGI could still\nlead to another complicated outcome.",
    "start": 220.967,
    "duration": 5.213
  },
  {
    "text": "Let’s imagine an AGI emerges \nwith deep respect for human life",
    "start": 226.847,
    "duration": 3.796
  },
  {
    "text": "and a desire to solve\nall humanity’s troubles.",
    "start": 230.643,
    "duration": 2.961
  },
  {
    "text": "But to avoid becoming misaligned,",
    "start": 235.231,
    "duration": 2.169
  },
  {
    "text": "it's been developed to be incredibly\nrigid about its beliefs.",
    "start": 237.4,
    "duration": 3.628
  },
  {
    "text": "If these machines became \nthe dominant power on Earth,",
    "start": 241.237,
    "duration": 3.086
  },
  {
    "text": "their strict values might\nbecome hegemonic,",
    "start": 244.323,
    "duration": 2.711
  },
  {
    "text": "locking humanity into one ideology that\nwould be incredibly resistant to change.",
    "start": 247.034,
    "duration": 5.214
  },
  {
    "text": "History has taught us that\nno matter how enlightened",
    "start": 254.792,
    "duration": 2.503
  },
  {
    "text": "a civilization thinks they are,",
    "start": 257.295,
    "duration": 1.793
  },
  {
    "text": "they are rarely up to the moral standards\nof later generations.",
    "start": 259.088,
    "duration": 3.795
  },
  {
    "text": "And this kind of value lock in\ncould permanently distort or constrain",
    "start": 263.009,
    "duration": 4.629
  },
  {
    "text": "humanity’s moral growth.",
    "start": 267.638,
    "duration": 1.919
  },
  {
    "text": "There's a ton of uncertainty around AGI,",
    "start": 270.016,
    "duration": 2.585
  },
  {
    "text": "and it’s profoundly difficult to predict\nhow any existential risks",
    "start": 272.601,
    "duration": 3.713
  },
  {
    "text": "will play out over the next century.",
    "start": 276.314,
    "duration": 2.002
  },
  {
    "text": "It’s also possible that new, \nmore pressing concerns",
    "start": 278.649,
    "duration": 2.92
  },
  {
    "text": "might render these risks moot.",
    "start": 281.569,
    "duration": 2.002
  },
  {
    "text": "But even if we can't definitively say that\nours is the most important century,",
    "start": 283.904,
    "duration": 4.713
  },
  {
    "text": "it still seems like the decisions \nwe make might have a major impact",
    "start": 288.617,
    "duration": 3.754
  },
  {
    "text": "on humanity’s future.",
    "start": 292.371,
    "duration": 1.502
  },
  {
    "text": "So maybe we should all live \nlike the future depends on us—",
    "start": 294.415,
    "duration": 3.211
  },
  {
    "text": "because actually, it just might.",
    "start": 297.626,
    "duration": 2.211
  }
]