[
  {
    "text": "So, I started my first job\nas a computer programmer",
    "start": 12.739,
    "duration": 4.122
  },
  {
    "text": "in my very first year of college --",
    "start": 16.885,
    "duration": 1.956
  },
  {
    "text": "basically, as a teenager.",
    "start": 18.865,
    "duration": 1.507
  },
  {
    "text": "Soon after I started working,",
    "start": 20.889,
    "duration": 1.732
  },
  {
    "text": "writing software in a company,",
    "start": 22.645,
    "duration": 1.61
  },
  {
    "text": "a manager who worked at the company\ncame down to where I was,",
    "start": 24.799,
    "duration": 3.635
  },
  {
    "text": "and he whispered to me,",
    "start": 28.458,
    "duration": 1.268
  },
  {
    "text": "\"Can he tell if I'm lying?\"",
    "start": 30.229,
    "duration": 2.861
  },
  {
    "text": "There was nobody else in the room.",
    "start": 33.806,
    "duration": 2.077
  },
  {
    "text": "\"Can who tell if you're lying?\nAnd why are we whispering?\"",
    "start": 37.032,
    "duration": 4.389
  },
  {
    "text": "The manager pointed\nat the computer in the room.",
    "start": 42.266,
    "duration": 3.107
  },
  {
    "text": "\"Can he tell if I'm lying?\"",
    "start": 45.397,
    "duration": 3.096
  },
  {
    "text": "Well, that manager was having\nan affair with the receptionist.",
    "start": 49.613,
    "duration": 4.362
  },
  {
    "text": "(Laughter)",
    "start": 53.999,
    "duration": 1.112
  },
  {
    "text": "And I was still a teenager.",
    "start": 55.135,
    "duration": 1.766
  },
  {
    "text": "So I whisper-shouted back to him,",
    "start": 57.447,
    "duration": 2.019
  },
  {
    "text": "\"Yes, the computer can tell\nif you're lying.\"",
    "start": 59.49,
    "duration": 3.624
  },
  {
    "text": "(Laughter)",
    "start": 63.138,
    "duration": 1.806
  },
  {
    "text": "Well, I laughed, but actually,\nthe laugh's on me.",
    "start": 64.968,
    "duration": 2.923
  },
  {
    "text": "Nowadays, there are computational systems",
    "start": 67.915,
    "duration": 3.268
  },
  {
    "text": "that can suss out\nemotional states and even lying",
    "start": 71.207,
    "duration": 3.548
  },
  {
    "text": "from processing human faces.",
    "start": 74.779,
    "duration": 2.044
  },
  {
    "text": "Advertisers and even governments\nare very interested.",
    "start": 77.248,
    "duration": 4.153
  },
  {
    "text": "I had become a computer programmer",
    "start": 82.319,
    "duration": 1.862
  },
  {
    "text": "because I was one of those kids\ncrazy about math and science.",
    "start": 84.205,
    "duration": 3.113
  },
  {
    "text": "But somewhere along the line\nI'd learned about nuclear weapons,",
    "start": 87.942,
    "duration": 3.108
  },
  {
    "text": "and I'd gotten really concerned\nwith the ethics of science.",
    "start": 91.074,
    "duration": 2.952
  },
  {
    "text": "I was troubled.",
    "start": 94.05,
    "duration": 1.204
  },
  {
    "text": "However, because of family circumstances,",
    "start": 95.278,
    "duration": 2.641
  },
  {
    "text": "I also needed to start working\nas soon as possible.",
    "start": 97.943,
    "duration": 3.298
  },
  {
    "text": "So I thought to myself, hey,\nlet me pick a technical field",
    "start": 101.265,
    "duration": 3.299
  },
  {
    "text": "where I can get a job easily",
    "start": 104.588,
    "duration": 1.796
  },
  {
    "text": "and where I don't have to deal\nwith any troublesome questions of ethics.",
    "start": 106.408,
    "duration": 4.018
  },
  {
    "text": "So I picked computers.",
    "start": 111.022,
    "duration": 1.529
  },
  {
    "text": "(Laughter)",
    "start": 112.575,
    "duration": 1.104
  },
  {
    "text": "Well, ha, ha, ha!\nAll the laughs are on me.",
    "start": 113.703,
    "duration": 3.41
  },
  {
    "text": "Nowadays, computer scientists\nare building platforms",
    "start": 117.137,
    "duration": 2.754
  },
  {
    "text": "that control what a billion\npeople see every day.",
    "start": 119.915,
    "duration": 4.209
  },
  {
    "text": "They're developing cars\nthat could decide who to run over.",
    "start": 125.052,
    "duration": 3.822
  },
  {
    "text": "They're even building machines, weapons,",
    "start": 129.707,
    "duration": 3.213
  },
  {
    "text": "that might kill human beings in war.",
    "start": 132.944,
    "duration": 2.285
  },
  {
    "text": "It's ethics all the way down.",
    "start": 135.253,
    "duration": 2.771
  },
  {
    "text": "Machine intelligence is here.",
    "start": 139.183,
    "duration": 2.058
  },
  {
    "text": "We're now using computation\nto make all sort of decisions,",
    "start": 141.823,
    "duration": 3.474
  },
  {
    "text": "but also new kinds of decisions.",
    "start": 145.321,
    "duration": 1.886
  },
  {
    "text": "We're asking questions to computation\nthat have no single right answers,",
    "start": 147.231,
    "duration": 5.172
  },
  {
    "text": "that are subjective",
    "start": 152.427,
    "duration": 1.202
  },
  {
    "text": "and open-ended and value-laden.",
    "start": 153.653,
    "duration": 2.325
  },
  {
    "text": "We're asking questions like,",
    "start": 156.002,
    "duration": 1.758
  },
  {
    "text": "\"Who should the company hire?\"",
    "start": 157.784,
    "duration": 1.65
  },
  {
    "text": "\"Which update from which friend\nshould you be shown?\"",
    "start": 160.096,
    "duration": 2.759
  },
  {
    "text": "\"Which convict is more\nlikely to reoffend?\"",
    "start": 162.879,
    "duration": 2.266
  },
  {
    "text": "\"Which news item or movie\nshould be recommended to people?\"",
    "start": 165.514,
    "duration": 3.054
  },
  {
    "text": "Look, yes, we've been using\ncomputers for a while,",
    "start": 168.592,
    "duration": 3.372
  },
  {
    "text": "but this is different.",
    "start": 171.988,
    "duration": 1.517
  },
  {
    "text": "This is a historical twist,",
    "start": 173.529,
    "duration": 2.067
  },
  {
    "text": "because we cannot anchor computation\nfor such subjective decisions",
    "start": 175.62,
    "duration": 5.337
  },
  {
    "text": "the way we can anchor computation\nfor flying airplanes, building bridges,",
    "start": 180.981,
    "duration": 5.42
  },
  {
    "text": "going to the moon.",
    "start": 186.425,
    "duration": 1.259
  },
  {
    "text": "Are airplanes safer?\nDid the bridge sway and fall?",
    "start": 188.449,
    "duration": 3.259
  },
  {
    "text": "There, we have agreed-upon,\nfairly clear benchmarks,",
    "start": 191.732,
    "duration": 4.498
  },
  {
    "text": "and we have laws of nature to guide us.",
    "start": 196.254,
    "duration": 2.239
  },
  {
    "text": "We have no such anchors and benchmarks",
    "start": 198.517,
    "duration": 3.394
  },
  {
    "text": "for decisions in messy human affairs.",
    "start": 201.935,
    "duration": 3.963
  },
  {
    "text": "To make things more complicated,\nour software is getting more powerful,",
    "start": 205.922,
    "duration": 4.237
  },
  {
    "text": "but it's also getting less\ntransparent and more complex.",
    "start": 210.183,
    "duration": 3.773
  },
  {
    "text": "Recently, in the past decade,",
    "start": 214.542,
    "duration": 2.04
  },
  {
    "text": "complex algorithms\nhave made great strides.",
    "start": 216.606,
    "duration": 2.729
  },
  {
    "text": "They can recognize human faces.",
    "start": 219.359,
    "duration": 1.99
  },
  {
    "text": "They can decipher handwriting.",
    "start": 221.985,
    "duration": 2.055
  },
  {
    "text": "They can detect credit card fraud",
    "start": 224.436,
    "duration": 2.066
  },
  {
    "text": "and block spam",
    "start": 226.526,
    "duration": 1.189
  },
  {
    "text": "and they can translate between languages.",
    "start": 227.739,
    "duration": 2.037
  },
  {
    "text": "They can detect tumors in medical imaging.",
    "start": 229.8,
    "duration": 2.574
  },
  {
    "text": "They can beat humans in chess and Go.",
    "start": 232.398,
    "duration": 2.205
  },
  {
    "text": "Much of this progress comes\nfrom a method called \"machine learning.\"",
    "start": 235.264,
    "duration": 4.504
  },
  {
    "text": "Machine learning is different\nthan traditional programming,",
    "start": 240.175,
    "duration": 3.187
  },
  {
    "text": "where you give the computer\ndetailed, exact, painstaking instructions.",
    "start": 243.386,
    "duration": 3.585
  },
  {
    "text": "It's more like you take the system\nand you feed it lots of data,",
    "start": 247.378,
    "duration": 4.182
  },
  {
    "text": "including unstructured data,",
    "start": 251.584,
    "duration": 1.656
  },
  {
    "text": "like the kind we generate\nin our digital lives.",
    "start": 253.264,
    "duration": 2.278
  },
  {
    "text": "And the system learns\nby churning through this data.",
    "start": 255.566,
    "duration": 2.73
  },
  {
    "text": "And also, crucially,",
    "start": 258.669,
    "duration": 1.526
  },
  {
    "text": "these systems don't operate\nunder a single-answer logic.",
    "start": 260.219,
    "duration": 4.38
  },
  {
    "text": "They don't produce a simple answer;\nit's more probabilistic:",
    "start": 264.623,
    "duration": 2.959
  },
  {
    "text": "\"This one is probably more like\nwhat you're looking for.\"",
    "start": 267.606,
    "duration": 3.483
  },
  {
    "text": "Now, the upside is:\nthis method is really powerful.",
    "start": 272.023,
    "duration": 3.07
  },
  {
    "text": "The head of Google's AI systems called it,",
    "start": 275.117,
    "duration": 2.076
  },
  {
    "text": "\"the unreasonable effectiveness of data.\"",
    "start": 277.217,
    "duration": 2.197
  },
  {
    "text": "The downside is,",
    "start": 279.791,
    "duration": 1.353
  },
  {
    "text": "we don't really understand\nwhat the system learned.",
    "start": 281.738,
    "duration": 3.071
  },
  {
    "text": "In fact, that's its power.",
    "start": 284.833,
    "duration": 1.587
  },
  {
    "text": "This is less like giving\ninstructions to a computer;",
    "start": 286.946,
    "duration": 3.798
  },
  {
    "text": "it's more like training\na puppy-machine-creature",
    "start": 291.2,
    "duration": 4.064
  },
  {
    "text": "we don't really understand or control.",
    "start": 295.288,
    "duration": 2.371
  },
  {
    "text": "So this is our problem.",
    "start": 298.362,
    "duration": 1.551
  },
  {
    "text": "It's a problem when this artificial\nintelligence system gets things wrong.",
    "start": 300.427,
    "duration": 4.262
  },
  {
    "text": "It's also a problem\nwhen it gets things right,",
    "start": 304.713,
    "duration": 3.54
  },
  {
    "text": "because we don't even know which is which\nwhen it's a subjective problem.",
    "start": 308.277,
    "duration": 3.628
  },
  {
    "text": "We don't know what this thing is thinking.",
    "start": 311.929,
    "duration": 2.339
  },
  {
    "text": "So, consider a hiring algorithm --",
    "start": 315.493,
    "duration": 3.683
  },
  {
    "text": "a system used to hire people,\nusing machine-learning systems.",
    "start": 320.123,
    "duration": 4.311
  },
  {
    "text": "Such a system would have been trained\non previous employees' data",
    "start": 325.052,
    "duration": 3.579
  },
  {
    "text": "and instructed to find and hire",
    "start": 328.655,
    "duration": 2.591
  },
  {
    "text": "people like the existing\nhigh performers in the company.",
    "start": 331.27,
    "duration": 3.038
  },
  {
    "text": "Sounds good.",
    "start": 334.814,
    "duration": 1.153
  },
  {
    "text": "I once attended a conference",
    "start": 335.991,
    "duration": 1.999
  },
  {
    "text": "that brought together\nhuman resources managers and executives,",
    "start": 338.014,
    "duration": 3.125
  },
  {
    "text": "high-level people,",
    "start": 341.163,
    "duration": 1.206
  },
  {
    "text": "using such systems in hiring.",
    "start": 342.393,
    "duration": 1.559
  },
  {
    "text": "They were super excited.",
    "start": 343.976,
    "duration": 1.646
  },
  {
    "text": "They thought that this would make hiring\nmore objective, less biased,",
    "start": 345.646,
    "duration": 4.653
  },
  {
    "text": "and give women\nand minorities a better shot",
    "start": 350.323,
    "duration": 3.0
  },
  {
    "text": "against biased human managers.",
    "start": 353.347,
    "duration": 2.188
  },
  {
    "text": "And look -- human hiring is biased.",
    "start": 355.559,
    "duration": 2.843
  },
  {
    "text": "I know.",
    "start": 359.099,
    "duration": 1.185
  },
  {
    "text": "I mean, in one of my early jobs\nas a programmer,",
    "start": 360.308,
    "duration": 3.005
  },
  {
    "text": "my immediate manager would sometimes\ncome down to where I was",
    "start": 363.337,
    "duration": 3.868
  },
  {
    "text": "really early in the morning\nor really late in the afternoon,",
    "start": 367.229,
    "duration": 3.753
  },
  {
    "text": "and she'd say, \"Zeynep,\nlet's go to lunch!\"",
    "start": 371.006,
    "duration": 3.062
  },
  {
    "text": "I'd be puzzled by the weird timing.",
    "start": 374.724,
    "duration": 2.167
  },
  {
    "text": "It's 4pm. Lunch?",
    "start": 376.915,
    "duration": 2.129
  },
  {
    "text": "I was broke, so free lunch. I always went.",
    "start": 379.068,
    "duration": 3.094
  },
  {
    "text": "I later realized what was happening.",
    "start": 382.618,
    "duration": 2.067
  },
  {
    "text": "My immediate managers\nhad not confessed to their higher-ups",
    "start": 384.709,
    "duration": 4.546
  },
  {
    "text": "that the programmer they hired\nfor a serious job was a teen girl",
    "start": 389.279,
    "duration": 3.113
  },
  {
    "text": "who wore jeans and sneakers to work.",
    "start": 392.416,
    "duration": 3.93
  },
  {
    "text": "I was doing a good job,\nI just looked wrong",
    "start": 397.174,
    "duration": 2.202
  },
  {
    "text": "and was the wrong age and gender.",
    "start": 399.4,
    "duration": 1.699
  },
  {
    "text": "So hiring in a gender- and race-blind way",
    "start": 401.123,
    "duration": 3.346
  },
  {
    "text": "certainly sounds good to me.",
    "start": 404.493,
    "duration": 1.865
  },
  {
    "text": "But with these systems,\nit is more complicated, and here's why:",
    "start": 407.031,
    "duration": 3.341
  },
  {
    "text": "Currently, computational systems\ncan infer all sorts of things about you",
    "start": 410.968,
    "duration": 5.791
  },
  {
    "text": "from your digital crumbs,",
    "start": 416.783,
    "duration": 1.872
  },
  {
    "text": "even if you have not\ndisclosed those things.",
    "start": 418.679,
    "duration": 2.333
  },
  {
    "text": "They can infer your sexual orientation,",
    "start": 421.506,
    "duration": 2.927
  },
  {
    "text": "your personality traits,",
    "start": 424.994,
    "duration": 1.306
  },
  {
    "text": "your political leanings.",
    "start": 426.859,
    "duration": 1.373
  },
  {
    "text": "They have predictive power\nwith high levels of accuracy.",
    "start": 428.83,
    "duration": 3.685
  },
  {
    "text": "Remember -- for things\nyou haven't even disclosed.",
    "start": 433.362,
    "duration": 2.578
  },
  {
    "text": "This is inference.",
    "start": 435.964,
    "duration": 1.591
  },
  {
    "text": "I have a friend who developed\nsuch computational systems",
    "start": 437.579,
    "duration": 3.261
  },
  {
    "text": "to predict the likelihood\nof clinical or postpartum depression",
    "start": 440.864,
    "duration": 3.641
  },
  {
    "text": "from social media data.",
    "start": 444.529,
    "duration": 1.416
  },
  {
    "text": "The results are impressive.",
    "start": 446.676,
    "duration": 1.427
  },
  {
    "text": "Her system can predict\nthe likelihood of depression",
    "start": 448.492,
    "duration": 3.357
  },
  {
    "text": "months before the onset of any symptoms --",
    "start": 451.873,
    "duration": 3.903
  },
  {
    "text": "months before.",
    "start": 455.8,
    "duration": 1.373
  },
  {
    "text": "No symptoms, there's prediction.",
    "start": 457.197,
    "duration": 2.246
  },
  {
    "text": "She hopes it will be used\nfor early intervention. Great!",
    "start": 459.467,
    "duration": 4.812
  },
  {
    "text": "But now put this in the context of hiring.",
    "start": 464.911,
    "duration": 2.04
  },
  {
    "text": "So at this human resources\nmanagers conference,",
    "start": 468.027,
    "duration": 3.046
  },
  {
    "text": "I approached a high-level manager\nin a very large company,",
    "start": 471.097,
    "duration": 4.709
  },
  {
    "text": "and I said to her, \"Look,\nwhat if, unbeknownst to you,",
    "start": 475.83,
    "duration": 4.578
  },
  {
    "text": "your system is weeding out people\nwith high future likelihood of depression?",
    "start": 480.432,
    "duration": 6.549
  },
  {
    "text": "They're not depressed now,\njust maybe in the future, more likely.",
    "start": 487.761,
    "duration": 3.376
  },
  {
    "text": "What if it's weeding out women\nmore likely to be pregnant",
    "start": 491.923,
    "duration": 3.406
  },
  {
    "text": "in the next year or two\nbut aren't pregnant now?",
    "start": 495.353,
    "duration": 2.586
  },
  {
    "text": "What if it's hiring aggressive people\nbecause that's your workplace culture?\"",
    "start": 498.844,
    "duration": 5.636
  },
  {
    "text": "You can't tell this by looking\nat gender breakdowns.",
    "start": 505.173,
    "duration": 2.691
  },
  {
    "text": "Those may be balanced.",
    "start": 507.888,
    "duration": 1.502
  },
  {
    "text": "And since this is machine learning,\nnot traditional coding,",
    "start": 509.414,
    "duration": 3.557
  },
  {
    "text": "there is no variable there\nlabeled \"higher risk of depression,\"",
    "start": 512.995,
    "duration": 4.907
  },
  {
    "text": "\"higher risk of pregnancy,\"",
    "start": 517.926,
    "duration": 1.833
  },
  {
    "text": "\"aggressive guy scale.\"",
    "start": 519.783,
    "duration": 1.734
  },
  {
    "text": "Not only do you not know\nwhat your system is selecting on,",
    "start": 521.995,
    "duration": 3.679
  },
  {
    "text": "you don't even know\nwhere to begin to look.",
    "start": 525.698,
    "duration": 2.323
  },
  {
    "text": "It's a black box.",
    "start": 528.045,
    "duration": 1.246
  },
  {
    "text": "It has predictive power,\nbut you don't understand it.",
    "start": 529.315,
    "duration": 2.807
  },
  {
    "text": "\"What safeguards,\" I asked, \"do you have",
    "start": 532.486,
    "duration": 2.369
  },
  {
    "text": "to make sure that your black box\nisn't doing something shady?\"",
    "start": 534.879,
    "duration": 3.673
  },
  {
    "text": "She looked at me as if I had\njust stepped on 10 puppy tails.",
    "start": 540.863,
    "duration": 3.878
  },
  {
    "text": "(Laughter)",
    "start": 544.765,
    "duration": 1.248
  },
  {
    "text": "She stared at me and she said,",
    "start": 546.037,
    "duration": 2.041
  },
  {
    "text": "\"I don't want to hear\nanother word about this.\"",
    "start": 548.556,
    "duration": 4.333
  },
  {
    "text": "And she turned around and walked away.",
    "start": 553.458,
    "duration": 2.034
  },
  {
    "text": "Mind you -- she wasn't rude.",
    "start": 556.064,
    "duration": 1.486
  },
  {
    "text": "It was clearly: what I don't know\nisn't my problem, go away, death stare.",
    "start": 557.574,
    "duration": 6.308
  },
  {
    "text": "(Laughter)",
    "start": 563.906,
    "duration": 1.246
  },
  {
    "text": "Look, such a system\nmay even be less biased",
    "start": 565.862,
    "duration": 3.839
  },
  {
    "text": "than human managers in some ways.",
    "start": 569.725,
    "duration": 2.103
  },
  {
    "text": "And it could make monetary sense.",
    "start": 571.852,
    "duration": 2.146
  },
  {
    "text": "But it could also lead",
    "start": 574.573,
    "duration": 1.65
  },
  {
    "text": "to a steady but stealthy\nshutting out of the job market",
    "start": 576.247,
    "duration": 4.748
  },
  {
    "text": "of people with higher risk of depression.",
    "start": 581.019,
    "duration": 2.293
  },
  {
    "text": "Is this the kind of society\nwe want to build,",
    "start": 583.753,
    "duration": 2.596
  },
  {
    "text": "without even knowing we've done this,",
    "start": 586.373,
    "duration": 2.285
  },
  {
    "text": "because we turned decision-making\nto machines we don't totally understand?",
    "start": 588.682,
    "duration": 3.964
  },
  {
    "text": "Another problem is this:",
    "start": 593.265,
    "duration": 1.458
  },
  {
    "text": "these systems are often trained\non data generated by our actions,",
    "start": 595.314,
    "duration": 4.452
  },
  {
    "text": "human imprints.",
    "start": 599.79,
    "duration": 1.816
  },
  {
    "text": "Well, they could just be\nreflecting our biases,",
    "start": 602.188,
    "duration": 3.808
  },
  {
    "text": "and these systems\ncould be picking up on our biases",
    "start": 606.02,
    "duration": 3.593
  },
  {
    "text": "and amplifying them",
    "start": 609.637,
    "duration": 1.313
  },
  {
    "text": "and showing them back to us,",
    "start": 610.974,
    "duration": 1.418
  },
  {
    "text": "while we're telling ourselves,",
    "start": 612.416,
    "duration": 1.462
  },
  {
    "text": "\"We're just doing objective,\nneutral computation.\"",
    "start": 613.902,
    "duration": 3.117
  },
  {
    "text": "Researchers found that on Google,",
    "start": 618.314,
    "duration": 2.677
  },
  {
    "text": "women are less likely than men\nto be shown job ads for high-paying jobs.",
    "start": 622.134,
    "duration": 5.313
  },
  {
    "text": "And searching for African-American names",
    "start": 628.463,
    "duration": 2.53
  },
  {
    "text": "is more likely to bring up ads\nsuggesting criminal history,",
    "start": 631.017,
    "duration": 4.706
  },
  {
    "text": "even when there is none.",
    "start": 635.747,
    "duration": 1.567
  },
  {
    "text": "Such hidden biases\nand black-box algorithms",
    "start": 638.693,
    "duration": 3.549
  },
  {
    "text": "that researchers uncover sometimes\nbut sometimes we don't know,",
    "start": 642.266,
    "duration": 3.973
  },
  {
    "text": "can have life-altering consequences.",
    "start": 646.263,
    "duration": 2.661
  },
  {
    "text": "In Wisconsin, a defendant\nwas sentenced to six years in prison",
    "start": 649.958,
    "duration": 4.159
  },
  {
    "text": "for evading the police.",
    "start": 654.141,
    "duration": 1.355
  },
  {
    "text": "You may not know this,",
    "start": 656.824,
    "duration": 1.186
  },
  {
    "text": "but algorithms are increasingly used\nin parole and sentencing decisions.",
    "start": 658.034,
    "duration": 3.998
  },
  {
    "text": "He wanted to know:\nHow is this score calculated?",
    "start": 662.056,
    "duration": 2.955
  },
  {
    "text": "It's a commercial black box.",
    "start": 665.795,
    "duration": 1.665
  },
  {
    "text": "The company refused to have its algorithm\nbe challenged in open court.",
    "start": 667.484,
    "duration": 4.205
  },
  {
    "text": "But ProPublica, an investigative\nnonprofit, audited that very algorithm",
    "start": 672.396,
    "duration": 5.532
  },
  {
    "text": "with what public data they could find,",
    "start": 677.952,
    "duration": 2.016
  },
  {
    "text": "and found that its outcomes were biased",
    "start": 679.992,
    "duration": 2.316
  },
  {
    "text": "and its predictive power\nwas dismal, barely better than chance,",
    "start": 682.332,
    "duration": 3.629
  },
  {
    "text": "and it was wrongly labeling\nblack defendants as future criminals",
    "start": 685.985,
    "duration": 4.416
  },
  {
    "text": "at twice the rate of white defendants.",
    "start": 690.425,
    "duration": 3.895
  },
  {
    "text": "So, consider this case:",
    "start": 695.891,
    "duration": 1.564
  },
  {
    "text": "This woman was late\npicking up her godsister",
    "start": 698.103,
    "duration": 3.852
  },
  {
    "text": "from a school in Broward County, Florida,",
    "start": 701.979,
    "duration": 2.075
  },
  {
    "text": "running down the street\nwith a friend of hers.",
    "start": 704.757,
    "duration": 2.356
  },
  {
    "text": "They spotted an unlocked kid's bike\nand a scooter on a porch",
    "start": 707.137,
    "duration": 4.099
  },
  {
    "text": "and foolishly jumped on it.",
    "start": 711.26,
    "duration": 1.632
  },
  {
    "text": "As they were speeding off,\na woman came out and said,",
    "start": 712.916,
    "duration": 2.599
  },
  {
    "text": "\"Hey! That's my kid's bike!\"",
    "start": 715.539,
    "duration": 2.205
  },
  {
    "text": "They dropped it, they walked away,\nbut they were arrested.",
    "start": 717.768,
    "duration": 3.294
  },
  {
    "text": "She was wrong, she was foolish,\nbut she was also just 18.",
    "start": 721.086,
    "duration": 3.637
  },
  {
    "text": "She had a couple of juvenile misdemeanors.",
    "start": 724.747,
    "duration": 2.544
  },
  {
    "text": "Meanwhile, that man had been arrested\nfor shoplifting in Home Depot --",
    "start": 727.808,
    "duration": 5.185
  },
  {
    "text": "85 dollars' worth of stuff,\na similar petty crime.",
    "start": 733.017,
    "duration": 2.924
  },
  {
    "text": "But he had two prior\narmed robbery convictions.",
    "start": 736.766,
    "duration": 4.559
  },
  {
    "text": "But the algorithm scored her\nas high risk, and not him.",
    "start": 741.955,
    "duration": 3.482
  },
  {
    "text": "Two years later, ProPublica found\nthat she had not reoffended.",
    "start": 746.746,
    "duration": 3.874
  },
  {
    "text": "It was just hard to get a job\nfor her with her record.",
    "start": 750.644,
    "duration": 2.55
  },
  {
    "text": "He, on the other hand, did reoffend",
    "start": 753.218,
    "duration": 2.076
  },
  {
    "text": "and is now serving an eight-year\nprison term for a later crime.",
    "start": 755.318,
    "duration": 3.836
  },
  {
    "text": "Clearly, we need to audit our black boxes",
    "start": 760.088,
    "duration": 3.369
  },
  {
    "text": "and not have them have\nthis kind of unchecked power.",
    "start": 763.481,
    "duration": 2.615
  },
  {
    "text": "(Applause)",
    "start": 766.12,
    "duration": 2.879
  },
  {
    "text": "Audits are great and important,\nbut they don't solve all our problems.",
    "start": 770.087,
    "duration": 4.242
  },
  {
    "text": "Take Facebook's powerful\nnews feed algorithm --",
    "start": 774.353,
    "duration": 2.748
  },
  {
    "text": "you know, the one that ranks everything\nand decides what to show you",
    "start": 777.125,
    "duration": 4.843
  },
  {
    "text": "from all the friends and pages you follow.",
    "start": 781.992,
    "duration": 2.284
  },
  {
    "text": "Should you be shown another baby picture?",
    "start": 784.898,
    "duration": 2.275
  },
  {
    "text": "(Laughter)",
    "start": 787.197,
    "duration": 1.196
  },
  {
    "text": "A sullen note from an acquaintance?",
    "start": 788.417,
    "duration": 2.596
  },
  {
    "text": "An important but difficult news item?",
    "start": 791.449,
    "duration": 1.856
  },
  {
    "text": "There's no right answer.",
    "start": 793.329,
    "duration": 1.482
  },
  {
    "text": "Facebook optimizes\nfor engagement on the site:",
    "start": 794.835,
    "duration": 2.659
  },
  {
    "text": "likes, shares, comments.",
    "start": 797.518,
    "duration": 1.415
  },
  {
    "text": "In August of 2014,",
    "start": 800.168,
    "duration": 2.696
  },
  {
    "text": "protests broke out in Ferguson, Missouri,",
    "start": 802.888,
    "duration": 2.662
  },
  {
    "text": "after the killing of an African-American\nteenager by a white police officer,",
    "start": 805.574,
    "duration": 4.417
  },
  {
    "text": "under murky circumstances.",
    "start": 810.015,
    "duration": 1.57
  },
  {
    "text": "The news of the protests was all over",
    "start": 811.974,
    "duration": 2.007
  },
  {
    "text": "my algorithmically\nunfiltered Twitter feed,",
    "start": 814.005,
    "duration": 2.685
  },
  {
    "text": "but nowhere on my Facebook.",
    "start": 816.714,
    "duration": 1.95
  },
  {
    "text": "Was it my Facebook friends?",
    "start": 819.182,
    "duration": 1.734
  },
  {
    "text": "I disabled Facebook's algorithm,",
    "start": 820.94,
    "duration": 2.032
  },
  {
    "text": "which is hard because Facebook\nkeeps wanting to make you",
    "start": 823.472,
    "duration": 2.848
  },
  {
    "text": "come under the algorithm's control,",
    "start": 826.344,
    "duration": 2.036
  },
  {
    "text": "and saw that my friends\nwere talking about it.",
    "start": 828.404,
    "duration": 2.238
  },
  {
    "text": "It's just that the algorithm\nwasn't showing it to me.",
    "start": 830.666,
    "duration": 2.509
  },
  {
    "text": "I researched this and found\nthis was a widespread problem.",
    "start": 833.199,
    "duration": 3.042
  },
  {
    "text": "The story of Ferguson\nwasn't algorithm-friendly.",
    "start": 836.265,
    "duration": 3.813
  },
  {
    "text": "It's not \"likable.\"",
    "start": 840.102,
    "duration": 1.171
  },
  {
    "text": "Who's going to click on \"like?\"",
    "start": 841.297,
    "duration": 1.552
  },
  {
    "text": "It's not even easy to comment on.",
    "start": 843.5,
    "duration": 2.206
  },
  {
    "text": "Without likes and comments,",
    "start": 845.73,
    "duration": 1.371
  },
  {
    "text": "the algorithm was likely showing it\nto even fewer people,",
    "start": 847.125,
    "duration": 3.292
  },
  {
    "text": "so we didn't get to see this.",
    "start": 850.441,
    "duration": 1.542
  },
  {
    "text": "Instead, that week,",
    "start": 852.946,
    "duration": 1.228
  },
  {
    "text": "Facebook's algorithm highlighted this,",
    "start": 854.198,
    "duration": 2.298
  },
  {
    "text": "which is the ALS Ice Bucket Challenge.",
    "start": 856.52,
    "duration": 2.226
  },
  {
    "text": "Worthy cause; dump ice water,\ndonate to charity, fine.",
    "start": 858.77,
    "duration": 3.742
  },
  {
    "text": "But it was super algorithm-friendly.",
    "start": 862.536,
    "duration": 1.904
  },
  {
    "text": "The machine made this decision for us.",
    "start": 865.219,
    "duration": 2.613
  },
  {
    "text": "A very important\nbut difficult conversation",
    "start": 867.856,
    "duration": 3.497
  },
  {
    "text": "might have been smothered,",
    "start": 871.377,
    "duration": 1.555
  },
  {
    "text": "had Facebook been the only channel.",
    "start": 872.956,
    "duration": 2.696
  },
  {
    "text": "Now, finally, these systems\ncan also be wrong",
    "start": 876.117,
    "duration": 3.797
  },
  {
    "text": "in ways that don't resemble human systems.",
    "start": 879.938,
    "duration": 2.736
  },
  {
    "text": "Do you guys remember Watson,\nIBM's machine-intelligence system",
    "start": 882.698,
    "duration": 2.922
  },
  {
    "text": "that wiped the floor\nwith human contestants on Jeopardy?",
    "start": 885.644,
    "duration": 3.128
  },
  {
    "text": "It was a great player.",
    "start": 889.131,
    "duration": 1.428
  },
  {
    "text": "But then, for Final Jeopardy,\nWatson was asked this question:",
    "start": 890.583,
    "duration": 3.569
  },
  {
    "text": "\"Its largest airport is named\nfor a World War II hero,",
    "start": 894.659,
    "duration": 2.932
  },
  {
    "text": "its second-largest\nfor a World War II battle.\"",
    "start": 897.615,
    "duration": 2.252
  },
  {
    "text": "(Hums Final Jeopardy music)",
    "start": 899.891,
    "duration": 1.378
  },
  {
    "text": "Chicago.",
    "start": 901.582,
    "duration": 1.182
  },
  {
    "text": "The two humans got it right.",
    "start": 902.788,
    "duration": 1.37
  },
  {
    "text": "Watson, on the other hand,\nanswered \"Toronto\" --",
    "start": 904.697,
    "duration": 4.348
  },
  {
    "text": "for a US city category!",
    "start": 909.069,
    "duration": 1.818
  },
  {
    "text": "The impressive system also made an error",
    "start": 911.596,
    "duration": 2.901
  },
  {
    "text": "that a human would never make,\na second-grader wouldn't make.",
    "start": 914.521,
    "duration": 3.651
  },
  {
    "text": "Our machine intelligence can fail",
    "start": 918.823,
    "duration": 3.109
  },
  {
    "text": "in ways that don't fit\nerror patterns of humans,",
    "start": 921.956,
    "duration": 3.1
  },
  {
    "text": "in ways we won't expect\nand be prepared for.",
    "start": 925.08,
    "duration": 2.95
  },
  {
    "text": "It'd be lousy not to get a job\none is qualified for,",
    "start": 928.054,
    "duration": 3.638
  },
  {
    "text": "but it would triple suck\nif it was because of stack overflow",
    "start": 931.716,
    "duration": 3.727
  },
  {
    "text": "in some subroutine.",
    "start": 935.467,
    "duration": 1.432
  },
  {
    "text": "(Laughter)",
    "start": 936.923,
    "duration": 1.579
  },
  {
    "text": "In May of 2010,",
    "start": 938.526,
    "duration": 2.786
  },
  {
    "text": "a flash crash on Wall Street\nfueled by a feedback loop",
    "start": 941.336,
    "duration": 4.044
  },
  {
    "text": "in Wall Street's \"sell\" algorithm",
    "start": 945.404,
    "duration": 3.028
  },
  {
    "text": "wiped a trillion dollars\nof value in 36 minutes.",
    "start": 948.456,
    "duration": 4.184
  },
  {
    "text": "I don't even want to think\nwhat \"error\" means",
    "start": 953.722,
    "duration": 2.187
  },
  {
    "text": "in the context of lethal\nautonomous weapons.",
    "start": 955.933,
    "duration": 3.589
  },
  {
    "text": "So yes, humans have always made biases.",
    "start": 961.894,
    "duration": 3.79
  },
  {
    "text": "Decision makers and gatekeepers,",
    "start": 965.708,
    "duration": 2.176
  },
  {
    "text": "in courts, in news, in war ...",
    "start": 967.908,
    "duration": 3.493
  },
  {
    "text": "they make mistakes;\nbut that's exactly my point.",
    "start": 971.425,
    "duration": 3.038
  },
  {
    "text": "We cannot escape\nthese difficult questions.",
    "start": 974.487,
    "duration": 3.521
  },
  {
    "text": "We cannot outsource\nour responsibilities to machines.",
    "start": 978.596,
    "duration": 3.516
  },
  {
    "text": "(Applause)",
    "start": 982.676,
    "duration": 4.208
  },
  {
    "text": "Artificial intelligence does not give us\na \"Get out of ethics free\" card.",
    "start": 989.089,
    "duration": 4.447
  },
  {
    "text": "Data scientist Fred Benenson\ncalls this math-washing.",
    "start": 994.742,
    "duration": 3.381
  },
  {
    "text": "We need the opposite.",
    "start": 998.147,
    "duration": 1.389
  },
  {
    "text": "We need to cultivate algorithm suspicion,\nscrutiny and investigation.",
    "start": 999.56,
    "duration": 5.388
  },
  {
    "text": "We need to make sure we have\nalgorithmic accountability,",
    "start": 1005.38,
    "duration": 3.198
  },
  {
    "text": "auditing and meaningful transparency.",
    "start": 1008.602,
    "duration": 2.445
  },
  {
    "text": "We need to accept\nthat bringing math and computation",
    "start": 1011.38,
    "duration": 3.234
  },
  {
    "text": "to messy, value-laden human affairs",
    "start": 1014.638,
    "duration": 2.97
  },
  {
    "text": "does not bring objectivity;",
    "start": 1017.632,
    "duration": 2.384
  },
  {
    "text": "rather, the complexity of human affairs\ninvades the algorithms.",
    "start": 1020.04,
    "duration": 3.633
  },
  {
    "text": "Yes, we can and we should use computation",
    "start": 1024.148,
    "duration": 3.487
  },
  {
    "text": "to help us make better decisions.",
    "start": 1027.659,
    "duration": 2.014
  },
  {
    "text": "But we have to own up\nto our moral responsibility to judgment,",
    "start": 1029.697,
    "duration": 5.332
  },
  {
    "text": "and use algorithms within that framework,",
    "start": 1035.053,
    "duration": 2.818
  },
  {
    "text": "not as a means to abdicate\nand outsource our responsibilities",
    "start": 1037.895,
    "duration": 4.935
  },
  {
    "text": "to one another as human to human.",
    "start": 1042.854,
    "duration": 2.454
  },
  {
    "text": "Machine intelligence is here.",
    "start": 1045.807,
    "duration": 2.609
  },
  {
    "text": "That means we must hold on ever tighter",
    "start": 1048.44,
    "duration": 3.421
  },
  {
    "text": "to human values and human ethics.",
    "start": 1051.885,
    "duration": 2.147
  },
  {
    "text": "Thank you.",
    "start": 1054.056,
    "duration": 1.154
  },
  {
    "text": "(Applause)",
    "start": 1055.234,
    "duration": 5.02
  }
]